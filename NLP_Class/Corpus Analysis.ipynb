{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb22f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Who's ahead in the pool for the third vaccine ...\n",
      "2     \"asymptomatic infection was reduced by 63 perc...\n",
      "3     > and appears to prevent the spread of the vir...\n",
      "4     The fact that there are multiple companies mak...\n",
      "5     Wow! This is such great news, and makes me hop...\n",
      "6     Scheduled to get my first round of the Moderna...\n",
      "7                 INTO MY ASS, RIGHT UP IN THERE PLEASE\n",
      "8     My 15th birthday is in March. I hope that by t...\n",
      "9     So how many healthcare workers in the US can /...\n",
      "10    As someone who worked on Moderna’s vaccine, I ...\n",
      "11    If J&J gets approved in January, normal in the...\n",
      "12    Any idea what kind of supply they have availab...\n",
      "13    Did the Moderna vaccine trials also exclude pe...\n",
      "14                     SHOVE IT IN ME YESTERDAY LETS GO\n",
      "15                Go get your flu shot in the meantime.\n",
      "16    My SIL is receiving this one next week. What i...\n",
      "17                                Send bobs and vaccine\n",
      "18    I’m going to sound dumb but is one vaccine bet...\n",
      "19    If this gets approved next week will it be jus...\n",
      "20    I'm a part of the Moderna trial and they infor...\n",
      "Name: comment_body, dtype: object\n",
      "Before:  34767\n",
      "After:  33221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('commentsRedditVaccines.csv')\n",
    "#this is to drop the bot comment \n",
    "data.drop(0,inplace=True)\n",
    "\n",
    "print(data.loc[0:20]['comment_body'])\n",
    "\n",
    "print(\"Before: \",len(data))\n",
    "removed=data[(data['comment_body']=='[removed]')].index\n",
    "deleted=data[(data['comment_body']=='[deleted]')].index\n",
    "data.drop(removed,inplace=True)\n",
    "data.drop(deleted,inplace=True)\n",
    "data.drop_duplicates()\n",
    "print(\"After: \",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7333804",
   "metadata": {},
   "source": [
    "### **The columns are:** \n",
    "'post_id', 'post_author', 'post_date', 'post_title', 'post_score','post_permalink', 'post_url', 'comment_id','comment_author','comment_date', 'comment_parent_id', 'comment_edited', 'comment_score','comment_body'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6fc74971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16131    Yassssss pleaseeee inject me with that science...\n",
       "18903    >There is no way to conclusively proof ANY new...\n",
       "31689    It is a terrible plan, one fuck up and hospita...\n",
       "18230              [relevant xkcd](https://xkcd.com/2391/)\n",
       "16010    I know what you are saying. I trust the scienc...\n",
       "3609     If only it could save us from the people who d...\n",
       "10416    What was your personal reaction? As someone wh...\n",
       "12552    Rushed? Do you think they started this from sc...\n",
       "25481    They have even been able to do some testing ph...\n",
       "33093    Yes, although most of us will probably just go...\n",
       "30058    >The pandemic is ending\\n\\nLol, have you looke...\n",
       "18284                 'Hol on...I'll be there in 21 hours.\n",
       "11181                                 Congrats, Canada! :D\n",
       "2757     Your comment has been removed because\\n\\n* **I...\n",
       "4834                                Thank you and I shall.\n",
       "1288     I'd think it not being approved here yet is wh...\n",
       "13781                                     It is indeed....\n",
       "28557    The Australian vaccine hasn’t worked (or rathe...\n",
       "13114    Some, yes. Not all, but some.\\n\\nTicketmaster ...\n",
       "31306                               No more tears formula!\n",
       "Name: comment_body, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of emojis, urls, and non-punctuation symbols like [ ]\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download(stopwords)\n",
    "from nltk.corpus import stopwords\n",
    "stopWords=stopwords.words('english')\n",
    "stopWords.extend(['.','?',',',\"n't\",\" ' \"])\n",
    "def symbolCleaner(text):\n",
    "    text=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text) #remove url\n",
    "    text=re.sub(r'[^\\w\\s]','',text) #idk this regex tbh\n",
    "    text=text.replace('\\n',' ')\n",
    "    text=text.replace('_',' ')\n",
    "    text=text.replace('\\t',' ')\n",
    "    text=text.replace('\\r',' ')\n",
    "    text=text.replace('gt',' ')\n",
    "    # https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "    emoji_pattern = re.compile(u\"[\"\n",
    "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "                        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "                        u\"\\U0001F600-\\U0001F64F\"\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                        u\"\\U0001f926-\\U0001f937\"\n",
    "                        u\"\\U00010000-\\U0010ffff\"\n",
    "                        u\"\\u2640-\\u2642\" \n",
    "                        u\"\\u2600-\\u2B55\"\n",
    "                        u\"\\u200d\"\n",
    "                        u\"\\u23cf\"\n",
    "                        u\"\\u23e9\"\n",
    "                        u\"\\u231a\"\n",
    "                        u\"\\ufe0f\"  # dingbats\n",
    "                        u\"\\u3030\"\n",
    "                        u\"\\U0001F493\"\n",
    "                        u\"\\U0001F1F2\"\n",
    "                        u\"\\U0001F1F4\"\n",
    "                        u\"\\U0001F620\"\n",
    "                        u\"\\U0001F602\"\n",
    "                        \"]+\", re.UNICODE)\n",
    "    text=emoji_pattern.sub(r'', text)\n",
    "    text=emoji.get_emoji_regexp().sub(u'', text)\n",
    "    text=re.sub('\\s+',' ',text)\n",
    "    return text\n",
    "\n",
    "def removeStopwords(tokens):\n",
    "    cleaned=[]\n",
    "    for v in tokens:\n",
    "            if v not in stopWords and len(v) > 0:\n",
    "                cleaned.append(v)\n",
    "    return cleaned\n",
    "\n",
    "# Randomly selecting 10,000 samples from the corpus\n",
    "randomSamples=data['comment_body'].sample(10000)\n",
    "randomSamples[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b206615",
   "metadata": {},
   "source": [
    "### Using VADER to label the samples before processing them for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "531d7c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yassssss pleaseeee inject me with that science...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;There is no way to conclusively proof ANY new...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is a terrible plan, one fuck up and hospita...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[relevant xkcd](https://xkcd.com/2391/)</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know what you are saying. I trust the scienc...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If only it could save us from the people who d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was your personal reaction? As someone wh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rushed? Do you think they started this from sc...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>They have even been able to do some testing ph...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes, although most of us will probably just go...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&gt;The pandemic is ending\\n\\nLol, have you looke...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'Hol on...I'll be there in 21 hours.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Congrats, Canada! :D</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Your comment has been removed because\\n\\n* **I...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thank you and I shall.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I'd think it not being approved here yet is wh...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>It is indeed....</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Australian vaccine hasn’t worked (or rathe...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Some, yes. Not all, but some.\\n\\nTicketmaster ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>No more tears formula!</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentiments    labels\n",
       "0   Yassssss pleaseeee inject me with that science...  Positive\n",
       "1   >There is no way to conclusively proof ANY new...  Positive\n",
       "2   It is a terrible plan, one fuck up and hospita...  Negative\n",
       "3             [relevant xkcd](https://xkcd.com/2391/)   Neutral\n",
       "4   I know what you are saying. I trust the scienc...  Negative\n",
       "5   If only it could save us from the people who d...  Positive\n",
       "6   What was your personal reaction? As someone wh...  Negative\n",
       "7   Rushed? Do you think they started this from sc...  Positive\n",
       "8   They have even been able to do some testing ph...  Positive\n",
       "9   Yes, although most of us will probably just go...  Positive\n",
       "10  >The pandemic is ending\\n\\nLol, have you looke...  Negative\n",
       "11               'Hol on...I'll be there in 21 hours.   Neutral\n",
       "12                               Congrats, Canada! :D  Positive\n",
       "13  Your comment has been removed because\\n\\n* **I...  Positive\n",
       "14                             Thank you and I shall.  Positive\n",
       "15  I'd think it not being approved here yet is wh...  Positive\n",
       "16                                   It is indeed....   Neutral\n",
       "17  The Australian vaccine hasn’t worked (or rathe...  Negative\n",
       "18  Some, yes. Not all, but some.\\n\\nTicketmaster ...  Positive\n",
       "19                             No more tears formula!  Negative"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_obj=SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentimentLabel(data):#this creates another dictionary of sentiments and labels, yes im too lazy to just rewrite over the previous dictionary cause we're in a hurry\n",
    "    sentiment_dict=sid_obj.polarity_scores(data)\n",
    "    if sentiment_dict['compound']>= 0.05:\n",
    "        label=\"Positive\"\n",
    "    elif sentiment_dict['compound']<= -0.05:\n",
    "        label=\"Negative\"\n",
    "    else:\n",
    "        label=\"Neutral\"\n",
    "    return {'sentiments':data,'labels':label}\n",
    "\n",
    "labelledSamples=pd.DataFrame([sentimentLabel(sample) for sample in randomSamples])\n",
    "labelledSamples[['sentiments','labels']][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c7fa4",
   "metadata": {},
   "source": [
    "### The samples after being cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "341aebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledSamples['sentiments']=labelledSamples['sentiments'].str.lower()\n",
    "labelledSamples['sentiments']=[removeStopwords(word_tokenize(sentiment)) for sentiment in labelledSamples['sentiments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "82750a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[yassssss, pleaseeee, inject, science, juice, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&gt;, way, conclusively, proof, new, legislation...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[terrible, plan, one, fuck, hospitals, way, be...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[, relevant, xkcd, ], (, https, :, //xkcd.com...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[know, saying, trust, science, trust, corporat...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[comments, like, stupid, really, expect, vacci...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[’, matter, companies, daycares, schools, etc,...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[first, ever, reddit, funded, scholarship, let...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[well, least, data, need, start, administering...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[ask, question, lot, nowadays, parents, live, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentiments    labels\n",
       "0     [yassssss, pleaseeee, inject, science, juice, ...  Positive\n",
       "1     [>, way, conclusively, proof, new, legislation...  Positive\n",
       "2     [terrible, plan, one, fuck, hospitals, way, be...  Negative\n",
       "3     [[, relevant, xkcd, ], (, https, :, //xkcd.com...   Neutral\n",
       "4     [know, saying, trust, science, trust, corporat...  Negative\n",
       "...                                                 ...       ...\n",
       "9995  [comments, like, stupid, really, expect, vacci...  Negative\n",
       "9996  [’, matter, companies, daycares, schools, etc,...   Neutral\n",
       "9997  [first, ever, reddit, funded, scholarship, let...  Positive\n",
       "9998  [well, least, data, need, start, administering...  Positive\n",
       "9999  [ask, question, lot, nowadays, parents, live, ...  Positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelledSamples[['sentiments','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "545ce448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [yassssss, pleaseeee, inject, science, juice, ...\n",
       "1    [>, way, conclusively, proof, new, legislation...\n",
       "2    [terrible, plan, one, fuck, hospitals, way, be...\n",
       "3    [[, relevant, xkcd, ], (, https, :, //xkcd.com...\n",
       "4    [know, saying, trust, science, trust, corporat...\n",
       "5               [could, save, us, people, believe, im]\n",
       "6    [personal, reaction, someone, allergies, news,...\n",
       "7    [rushed, think, started, scratch, like, year, ...\n",
       "8    [even, able, testing, phases, overlapping, tim...\n",
       "9    [yes, although, us, probably, go, moderna, man...\n",
       "Name: sentiments, dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelledSamples['sentiments'][0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
